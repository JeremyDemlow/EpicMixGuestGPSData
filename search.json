[
  {
    "objectID": "gps_poc.html",
    "href": "gps_poc.html",
    "title": "Epic Mix Guest GPS POC",
    "section": "",
    "text": "This is the first data source need for the GPS POC wait times development project.\nAs of right now we are most likely going to be taking advantage of the Databricks Spark Engine or we might move it completely to a Snowpark Engine, which really the same thing, but both are under development in which one works best for the future prospects of the company."
  },
  {
    "objectID": "gps_poc.html#functions",
    "href": "gps_poc.html#functions",
    "title": "Epic Mix Guest GPS POC",
    "section": "Functions",
    "text": "Functions\n\nprocess_coordinate_string\n\nsource\n\n\nprocess_coordinate_string\n\n process_coordinate_string (str)\n\n\n\nkml2csv\n\nsource\n\n\nkml2csv\n\n kml2csv (fname)\n\nOpen the KML. Read the KML. Open a CSV file. Process a coordinate string to be a CSV row. Input: Filename with extension (‘example.kml’), located in ‘kml’ folder. Output: File with the same name as input, but in .csv format, located in ‘csv’ folder.\n\n\ncreate_circle_area_around_lifts\n\nsource\n\n\ncreate_circle_area_around_lifts\n\n create_circle_area_around_lifts (df_lifts, file_name:str,\n                                  kml_file_dir:str=None,\n                                  number_of_vertices:int=36,\n                                  radius:int=30, delete_kml:bool=True)"
  },
  {
    "objectID": "gps_poc.html#example",
    "href": "gps_poc.html#example",
    "title": "Epic Mix Guest GPS POC",
    "section": "Example",
    "text": "Example\nThis will be the part that needs the most work from this POC perspective as the creations of differing circle sizes is not the challenge right now the challenge is to create appropriate centroids to the lift mazes so that we can create better locations rather than something as follows:\n\n\n\nimage.png\n\n\nRight now we are going to run into over laps because of the size but additionally lifts are close together what could really fix this would be the idea that we weren’t stuck to the geo lat/lon of where the lift is exactly and this overlap wouldn’t be much of an issue.\nSeen below is a radius of 40 meters so making them smaller to a 30 default is what you can see inside of the functional call, but again the size of the circle is the easiest part of all of this.\n\n\n\nimage.png\n\n\nWhat this would look like if we changed the centroid this is what we will be looking to do with this simple change\n\nfrom data_system_utilities.snowflake.query import Snowflake\nfrom data_system_utilities.snowflake.utils import create_table_query_from_df\nfrom matplotlib import pyplot as plt\n\n/opt/hostedtoolcache/Python/3.9.15/x64/lib/python3.9/site-packages/snowflake/connector/options.py:96: UserWarning: You have an incompatible version of 'pyarrow' installed (6.0.0), please install a version that adheres to: 'pyarrow<8.1.0,>=8.0.0; extra == \"pandas\"'\n  warn_incompatible_dep(\nINFO:matplotlib.font_manager:Failed to extract font properties from /usr/share/fonts/truetype/noto/NotoColorEmoji.ttf: In FT2Font: Can not load face (unknown file format; error code 0x2)\nINFO:matplotlib.font_manager:generated new fontManager\n\n\n\n# Pulling in current lift lat long data locations\nsf = Snowflake(\n    sfAccount=os.environ['sfAccount'],\n    sfUser=os.environ['sfUser'],\n    sfPswd=os.environ['sfPswd'],\n    sfWarehouse=os.environ['sfWarehouse'],\n    sfDatabase=os.environ['sfDatabase'],\n    sfSchema=os.environ['sfSchema'],\n    sfRole=os.environ['sfRole']\n)\n\ndf_lifts = sf.run_sql_str('''SELECT * \n    FROM ONMOUNTAIN.PROD.LIFTDIMENSIONS\n    WHERE LATITUDE IS NOT NULL AND LONGITUDE IS NOT NULL\n'''\n)\ndf_lifts.columns = [x.lower() for x in df_lifts.columns]\ndf_lifts = df_lifts[['resortname','resortkey', 'liftname', 'latitude', 'longitude']]\ndisplay(df_lifts.head())\nos.makedirs('./testlift/', exist_ok=True)\ndf_lat_lon = create_circle_area_around_lifts(df_lifts, \n                                            file_name='point_kml.kml',\n                                            kml_file_dir='./testlift/',\n                                            delete_kml=True)\ndisplay(df_lat_lon.head())\n\n# create new snowflake data asset\nsf = Snowflake(\n    sfAccount=os.environ['sfAccount'],\n    sfUser=os.environ['sfUser'],\n    sfPswd=os.environ['sfPswd'],\n    sfWarehouse=os.environ['sfWarehouse'],\n    sfDatabase=os.environ['sfDatabase'],\n    sfSchema='WAITTIMES',\n    sfRole=os.environ['sfRole']\n)\ntable_query = create_table_query_from_df(df_lat_lon, \n                                        'MACHINELEARNINGOUTPUTS.WAITTIMES.lat_lon_lift_circle_waitime_qa',\n                                        True)\nsf.run_sql_str(table_query)\nsf.infer_to_snowflake(df=df_lat_lon, table_name='lat_lon_lift_circle_waitime_qa', if_exists='replace')\nsf.run_sql_str('''SELECT *\n               FROM lat_lon_lift_circle_waitime_qa\n               where liftname = 'Arrow Bahn'\n               LIMIT 5\n               ''')\n\n# quick check to see if the function is working as intended\nlift_name = 'Arrow Bahn'\nplt.plot(df_lat_lon[df_lat_lon.LIFTNAME == lift_name].LAT,  df_lat_lon[df_lat_lon.LIFTNAME == lift_name].LON)\nplt.show()\n\nINFO:data_system_utilities.snowflake.utils:connection to snowflake established...\nINFO:data_system_utilities.snowflake.query:executing query\nINFO:data_system_utilities.snowflake.query:data loaded from snowflake\nINFO:data_system_utilities.snowflake.query:connection to snowflake has been turned off\n\n\n\n\n\n\n  \n    \n      \n      resortname\n      resortkey\n      liftname\n      latitude\n      longitude\n    \n  \n  \n    \n      0\n      Beaver Creek Resort\n      2\n      Arrow Bahn\n      39.632572\n      -106.562612\n    \n    \n      1\n      Beaver Creek Resort\n      2\n      Bachelor Gulch Express\n      39.622782\n      -106.541801\n    \n    \n      2\n      Beaver Creek Resort\n      2\n      Birds of Prey Express\n      39.585960\n      -106.525253\n    \n    \n      3\n      Beaver Creek Resort\n      2\n      Centennial Express\n      39.602749\n      -106.516956\n    \n    \n      4\n      Beaver Creek Resort\n      2\n      Cinch Express\n      39.582695\n      -106.508131\n    \n  \n\n\n\n\nINFO:root:Total number of lifts being updated 245\n\n\n\n\n\n\n  \n    \n      \n      lat\n      lon\n      liftname\n      resortname\n      resortkey\n    \n  \n  \n    \n      0\n      39.632838\n      -106.562551\n      Arrow Bahn\n      Beaver Creek Resort\n      2\n    \n    \n      1\n      39.632826\n      -106.562492\n      Arrow Bahn\n      Beaver Creek Resort\n      2\n    \n    \n      2\n      39.632806\n      -106.562437\n      Arrow Bahn\n      Beaver Creek Resort\n      2\n    \n    \n      3\n      39.632779\n      -106.562387\n      Arrow Bahn\n      Beaver Creek Resort\n      2\n    \n    \n      4\n      39.632746\n      -106.562344\n      Arrow Bahn\n      Beaver Creek Resort\n      2\n    \n  \n\n\n\n\nINFO:root:\n        create or replace table MACHINELEARNINGOUTPUTS.WAITTIMES.lat_lon_lift_circle_waitime_qa (lat VARCHAR, lon VARCHAR, liftname VARCHAR, resortname VARCHAR, resortkey VARCHAR);\n        \nINFO:data_system_utilities.snowflake.utils:connection to snowflake established...\nINFO:data_system_utilities.snowflake.query:executing query\nINFO:data_system_utilities.snowflake.query:data loaded from snowflake\nINFO:data_system_utilities.snowflake.query:connection to snowflake has been turned off\nINFO:data_system_utilities.snowflake.query:Table LAT_LON_LIFT_CIRCLE_WAITIME_QA successfully created.\nINFO:data_system_utilities.snowflake.query:creating table lat_lon_lift_circle_waitime_qa\nINFO:data_system_utilities.snowflake.query:sqlalchemy snowflake engine created\nINFO:data_system_utilities.snowflake.query:table created\nINFO:data_system_utilities.snowflake.utils:connection to snowflake established...\nINFO:data_system_utilities.snowflake.query:executing query\nINFO:data_system_utilities.snowflake.query:data loaded from snowflake\nINFO:data_system_utilities.snowflake.query:connection to snowflake has been turned off"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "EpicMixGuestGPSData",
    "section": "",
    "text": "Why?\nCurrently this isn’t something that is fully baked out, but this will become the living documentation where it will be able to make calls an update the documentation live from each and every push. This project is going to be the area where Jeremy Demlow begins to develop a template for those that like the process that nbdev give a developer.\nThis means there will be issues and that he is going to welcome all and any feedback from anyone working in this process flow. DSU and MSU are examples of where nbdev is flexing into different work flows, but this process will be strictly using nbdev as the process choice of development.\nThings to develop out:\n\nChoosing the engine of choice\n\nChoosing the engine will then desire a data checking system like great expectations and using ELT process like DBT to allow for all of this data to be tested and true QA processes.\nThings like dbx from databricks that is a process in which helps schedule jobs, which right now that is a lot of work and research into how to make something like that work as interactivity to databricks is crucial for the type of development we want to do for all projects from RDE data sets to a specific modeling data set that we want. Spark Connect Jira Ticket\n\nDeveloping out some sort of sudo modeling approach\nMany other small things that are going to become more apparent as this development process grows.\n\n\n\nGPS POC Module\nThis module is have a process that can quickly create geo circles around a lat/long position to be able to begin write out logic for capturing time with in a “maze” to get onto a lift. Tons and tons of development will need to be done to get this part out, but that is where we are moving sooner than later."
  }
]