{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "# from EpicMixGuestGPSData.poc_gps import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EpicMixGuestGPSData\n",
    "\n",
    "> Vail GPS Poc Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```sh\n",
    "pip install EpicMixGuestGPSData\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Currently this isn't something that is fully baked out, but this will become the living documentation where it will be able to make calls an update the documentation live from each and every push. This project is going to be the area where Jeremy Demlow begins to develop a template for those that like the process that nbdev give a developer.\n",
    "\n",
    "This means there will be issues and that he is going to welcome all and any feedback from anyone working in this process flow. DSU and MSU are examples of where nbdev is flexing into different work flows, but this process will be strictly using nbdev as the process choice of development. \n",
    "\n",
    "Things to develop out:\n",
    "\n",
    "1. Choosing the engine of choice\n",
    "\n",
    "    a. Choosing the engine will then desire a data checking system like great expectations and using ELT process like DBT to allow for all of this data to be tested and true QA processes.\n",
    "    \n",
    "    b. Things like dbx from databricks that is a process in which helps schedule jobs, which right now that is a lot of work and research into how to make something like that work as interactivity to databricks is crucial for the type of development we want to do for all projects from RDE data sets to a specific modeling data set that we want. [Spark Connect](https://www.databricks.com/blog/2022/07/07/introducing-spark-connect-the-power-of-apache-spark-everywhere.html) [Jira Ticket](https://issues.apache.org/jira/browse/SPARK-39375)\n",
    "    \n",
    "2. Developing out some sort of sudo modeling approach\n",
    "\n",
    "3. Many other small things that are going to become more apparent as this development process grows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPS POC Module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This module is have a process that can quickly create geo circles around a lat/long position to be able to begin write out logic for capturing time with in a \"maze\" to get onto a lift. Tons and tons of development will need to be done to get this part out, but that is where we are moving sooner than later. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
